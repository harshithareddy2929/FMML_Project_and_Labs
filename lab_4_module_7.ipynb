{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPOtPr13023s+OXhX+fHwen",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshithareddy2929/FMML_Project_and_Labs/blob/main/lab_4_module_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Excercise 1 (Histogram based Anomaly Detection)\n",
        "##Is a simple classification algorithm suitable for anomaly detection? (Hint - Is accuracy the correct metric?)\n",
        "Anomaly detection typically involves identifying patterns or instances that deviate significantly from the norm or expected behavior. While simple classification algorithms can be used for anomaly detection, they might not always be the most suitable choice, especially when dealing with imbalanced datasets where anomalies are rare compared to normal instances.\n",
        "\n",
        "Accuracy may not be the correct metric for evaluating the performance of an anomaly detection system. This is because accuracy can be misleading in imbalanced datasets, where the majority class (normal instances) dominates the accuracy calculation, and the model may appear to perform well even if it fails to detect anomalies effectively.\n",
        "\n",
        "Commonly used metrics for evaluating anomaly detection models include:\n",
        "\n",
        "##Precision-Recall (PR) Curve:\n",
        "\n",
        "Precision measures the accuracy of the positive predictions, focusing on the correctness of detected anomalies.\n",
        "Recall (sensitivity) measures the ability of the model to capture all anomalies.\n",
        "##Area Under the Receiver Operating Characteristic (ROC-AUC):\n",
        "\n",
        "ROC-AUC is a metric that evaluates the trade-off between true positive rate and false positive rate.\n",
        "A higher ROC-AUC generally indicates better performance.\n",
        "##F1 Score:\n",
        "\n",
        "The F1 score combines precision and recall into a single metric, providing a balance between the two.\n",
        "##Confusion Matrix:\n",
        "\n",
        "Examining the confusion matrix can give insights into the true positives, false positives, true negatives, and false negatives.\n",
        "When selecting a classification algorithm for anomaly detection, it's important to consider the nature of your data and the specific requirements of your application. Some algorithms that are commonly used for anomaly detection include isolation forests, one-class SVM, and autoencoders.\n",
        "\n",
        "In summary, while simple classification algorithms can be used for anomaly detection, careful consideration of metrics and the choice of algorithm is crucial for effective evaluation and performance.\n",
        "#Exercise 2\n",
        "##What is a mathematical way for anomaly detection? (Hint - Model data to be Gaussian distribution / Does the Reverse Nearest Neighbour reveal something about the anomalies?)\n",
        "One mathematical approach for anomaly detection involves modeling the data distribution, often assuming that the normal instances follow a certain distribution, such as a Gaussian distribution (normal distribution). This approach is commonly used in statistical-based anomaly detection methods. The key idea is to identify instances that deviate significantly from the expected distribution as potential anomalies.\n",
        "\n",
        "Here are a couple of methods based on mathematical principles:\n",
        "\n",
        "##Gaussian Distribution Modeling:\n",
        "\n",
        "Assume that the normal instances in your dataset follow a Gaussian distribution.\n",
        "Use statistical parameters such as mean and standard deviation to characterize the distribution.\n",
        "Instances that fall outside a certain threshold (based on standard deviations) can be considered anomalies.\n",
        "##Reverse Nearest Neighbors (RNN):\n",
        "\n",
        "Reverse Nearest Neighbors is a technique that explores the relationships between data points.\n",
        "For each data point, identify its nearest neighbors.\n",
        "If a point has fewer or significantly different nearest neighbors compared to the majority, it might be an anomaly.\n",
        "This method is particularly useful when anomalies are expected to have different local density patterns.\n",
        "Both of these methods leverage mathematical principles to identify anomalies, but they approach the problem from different angles. Gaussian distribution modeling assumes a specific form for the normal instances' distribution, while Reverse Nearest Neighbors focuses on the relationships between data points.\n",
        "\n",
        "It's worth noting that the choice of method depends on the characteristics of your data and the nature of anomalies you are trying to detect. Additionally, combining multiple techniques or using machine learning approaches like isolation forests or one-class SVMs can enhance the performance of anomaly detection systems.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OjQEvUY6K8OR"
      }
    }
  ]
}