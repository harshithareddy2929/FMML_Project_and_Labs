{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsKcYowt1HXegN9clVGd0Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshithareddy2929/FMML_Project_and_Labs/blob/main/lab_3_module_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q1)How exactly does matrix factorization help us in the recommendation procedure? Why can we not simply model the user-movie matrix?\n",
        "Matrix factorization is a technique commonly used in recommendation systems to extract latent features from user-item interaction data. The user-movie matrix in a recommendation system represents the ratings or interactions between users and movies. However, modeling this matrix directly has several challenges and limitations, which matrix factorization aims to address. Here's how matrix factorization helps in the recommendation procedure:\n",
        "\n",
        "##1)Sparsity:\n",
        "\n",
        "User-movie matrices are often sparse because not all users have rated all movies. This sparsity makes it challenging to identify patterns and relationships within the data. Matrix factorization helps overcome sparsity by approximating the original matrix with the product of two lower-dimensional matrices (user and item matrices). These lower-dimensional matrices capture latent features that contribute to the user-item interactions.\n",
        "##2)Dimensionality Reduction:\n",
        "\n",
        "The inherent dimensionality of the user-movie matrix can be very high, especially when dealing with a large number of users and items. Matrix factorization reduces the dimensionality by representing users and items in a lower-dimensional space, making it computationally more efficient and reducing the risk of overfitting.\n",
        "##3)Generalization:\n",
        "\n",
        "Matrix factorization allows for better generalization to new users and items. By learning latent features, the model can make predictions for users and items with limited or no historical interaction. This is particularly useful in real-world scenarios where new users or items are constantly introduced to the system.\n",
        "##4)Personalization:\n",
        "\n",
        "Matrix factorization enables personalized recommendations by capturing the unique preferences of each user and the characteristics of each item. The latent features represent abstract properties of users and items, such as genres, actors, or themes, which are not explicitly provided in the original data.\n",
        "##5)Collaborative Filtering:\n",
        "\n",
        "Matrix factorization is a form of collaborative filtering. It identifies latent factors that capture the underlying patterns in user-item interactions. By leveraging the preferences and behaviors of similar users, the model can recommend items to a user based on the preferences of users with similar tastes.\n",
        "##6)Handling Missing Data:\n",
        "\n",
        "Matrix factorization inherently handles missing data, as it can make predictions for unobserved entries in the original matrix. This is valuable in recommendation systems where users have not rated or interacted with all items.\n",
        "\n",
        "In summary, matrix factorization helps overcome the challenges of sparsity, high dimensionality, and lack of generalization in user-movie matrices. It provides a more efficient and effective way to model user-item interactions, leading to improved recommendations in collaborative filtering-based recommendation systems.\n",
        "#Q2)What do the rows of the matrix  T  represent? (Definition of  T  is above in the introduction to LSI).\n",
        "In Latent Semantic Indexing (LSI), the matrix T represents the term-concept vector matrix. The rows of this matrix (T i) correspond to the terms or unique words in the original corpus. Each row captures the association of a term with the underlying latent concepts identified by the LSI model.\n",
        "\n",
        "Mathematically, if T is an m x r  where m is the number of unique terms and r is the number of latent semantic dimensions (topics), then T is the i-th row vector of T.\n",
        "\n",
        "The values in T indicate how strongly the term represented by the i-th row is associated with each of the latent semantic dimensions. These values are learned during the SVD (Singular Value Decomposition) process and capture the underlying relationships between terms and concepts in the corpus.\n",
        "\n",
        "In the context of information retrieval or document similarity, the rows of matrix T can be used to represent the terms in a lower-dimensional space, where terms with similar meanings or contexts are closer together. This enables more effective and efficient analysis of relationships between terms and documents in the corpus."
      ],
      "metadata": {
        "id": "TxmmjZYva4ve"
      }
    }
  ]
}